# -*- coding: utf-8 -*-
"""Tarea 2 CdD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1giodVfc6VEdIQA7RnQ1hUsHVJz0P8Rbf
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import OneHotEncoder, StandardScaler

file_path = '/content/drive/MyDrive/Tercer Semestre/Introducción a la Ciencia de Datos/Datasets/bank-full.csv'

df = pd.read_csv(file_path, sep = ";")
#Primeras filas
print("\n --- Primeras filas del DataFrame ---")
print(df.head())


# ==========================================================
# Exploración inicial de la base de datos df
# ==========================================================

# 1) Revisemos los tipos de datos de cada columna
print("\n--- Tipos de datos ---")
print(df.dtypes)

# 2) Verifiquemos si existen valores faltantes en las columnas
print("\n--- Valores faltantes por columna ---")
print(df.isnull().sum())

# Nota: en este dataset los 'missing' no suelen estar como NaN,
# sino como la categoría 'unknown' en varias variables.
print("\n--- Conteo de 'unknown' por columna ---")
unknown_counts = (df.applymap(lambda x: str(x).lower() == "unknown")).sum()
print(unknown_counts[unknown_counts > 0])

# 3) Revisemos si hay filas duplicadas
print("\n--- Número de filas duplicadas ---")
print(df.duplicated().sum())

# 4) Obtenemos un resumen estadístico de las columnas numéricas
print("\n--- Resumen estadístico de columnas numéricas ---")
print(df.describe())

# 5) Revisamos un resumen de columnas categóricas (tipo objeto)
print("\n--- Resumen de columnas categóricas ---")
print(df.describe(include=['object']))

# 6) Mostramos la dimensión de la base de datos
print("\n--- Dimensión de la base de datos (filas, columnas) ---")
print(df.shape)

# 7) Distribución de la variable respuesta 'y'
print("\n--- Distribución de la variable objetivo (y) ---")
print(df['y'].value_counts())
print("\n--- Distribución porcentual ---")
print(df['y'].value_counts(normalize=True).mul(100).round(2))

# ==========================================================
# Preprocesamiento
# ==========================================================

# a) Eliminamos espacios en blanco y pasamos a minúsculas las variables categóricas
for col in df.select_dtypes(include=['object']).columns:
    df[col] = df[col].str.strip().str.lower()

# b) Convertimos la variable respuesta 'y' a binaria (0 = no, 1 = yes)
df['y'] = df['y'].map({'no': 0, 'yes': 1})

# c) Identificamos variables numéricas y categóricas
num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
cat_cols = df.select_dtypes(include=['object']).columns.tolist()
cat_cols = [c for c in cat_cols if c != 'y']

print("\n--- Variables numéricas ---")
print(num_cols)
print("\n--- Variables categóricas ---")
print(cat_cols)

# d) Codificación One-Hot para categóricas
df_encoded = pd.get_dummies(df, columns=cat_cols, drop_first=True)

print("\n--- DataFrame tras One-Hot Encoding ---")
print(df_encoded.head())

# e) Escalado de variables numéricas
scaler = StandardScaler()
df_encoded[num_cols] = scaler.fit_transform(df_encoded[num_cols])

print("\n--- Variables numéricas estandarizadas ---")
print(df_encoded[num_cols].head())

# f) Separamos predictores (X) y variable respuesta (y)
X = df_encoded.drop('y', axis=1)
y = df_encoded['y']

print("\n--- Dimensiones finales ---")
print("X:", X.shape)
print("y:", y.shape)